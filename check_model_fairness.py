#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¨¡å‹å…¬å¹³æ€§æ£€æµ‹å·¥å…·
ç”¨äºåœ¨æ¨¡å‹è®­ç»ƒåæ£€æµ‹å…¬å¹³æ€§å’Œåè§
"""

import pandas as pd
import numpy as np
import os
import sys
from base.base_fairness_processor import FairnessChecker, identify_potential_sensitive_features

def load_training_data_with_predictions():
    """
    åŠ è½½è®­ç»ƒæ•°æ®å’Œæ¨¡å‹é¢„æµ‹ç»“æœ
    
    è¿”å›:
    DataFrame: åŒ…å«æ ‡ç­¾å’Œé¢„æµ‹ç»“æœçš„æ•°æ®æ¡†
    """
    try:
        # åŠ è½½è®­ç»ƒæ•°æ®
        train_data_path = "data_train/train.csv"
        if not os.path.exists(train_data_path):
            print(f"âŒ æ‰¾ä¸åˆ°è®­ç»ƒæ•°æ®æ–‡ä»¶: {train_data_path}")
            return None
            
        print(f"æ­£åœ¨åŠ è½½è®­ç»ƒæ•°æ®: {train_data_path}")
        train_df = pd.read_csv(train_data_path)
        print(f"âœ… è®­ç»ƒæ•°æ®åŠ è½½å®Œæˆï¼Œå½¢çŠ¶: {train_df.shape}")
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«Labelåˆ—
        if 'Label' not in train_df.columns:
            print("âŒ è®­ç»ƒæ•°æ®ä¸­æœªæ‰¾åˆ°Labelåˆ—")
            return None
            
        return train_df
        
    except Exception as e:
        print(f"âŒ åŠ è½½è®­ç»ƒæ•°æ®æ—¶å‡ºé”™: {e}")
        return None

def load_prediction_results():
    """
    åŠ è½½é¢„æµ‹ç»“æœ
    
    è¿”å›:
    DataFrame: åŒ…å«é¢„æµ‹ç»“æœçš„æ•°æ®æ¡†
    """
    try:
        # åŠ è½½é¢„æµ‹ç»“æœ
        prediction_path = "output/prediction_results.csv"
        if not os.path.exists(prediction_path):
            print(f"âŒ æ‰¾ä¸åˆ°é¢„æµ‹ç»“æœæ–‡ä»¶: {prediction_path}")
            return None
            
        print(f"æ­£åœ¨åŠ è½½é¢„æµ‹ç»“æœ: {prediction_path}")
        pred_df = pd.read_csv(prediction_path)
        print(f"âœ… é¢„æµ‹ç»“æœåŠ è½½å®Œæˆï¼Œå½¢çŠ¶: {pred_df.shape}")
        
        # æ£€æŸ¥å¿…éœ€çš„åˆ—
        required_columns = ['Id', 'PredictedProb']
        missing_columns = [col for col in required_columns if col not in pred_df.columns]
        if missing_columns:
            print(f"âŒ é¢„æµ‹ç»“æœä¸­ç¼ºå°‘å¿…éœ€çš„åˆ—: {missing_columns}")
            return None
            
        return pred_df
        
    except Exception as e:
        print(f"âŒ åŠ è½½é¢„æµ‹ç»“æœæ—¶å‡ºé”™: {e}")
        return None

def perform_fairness_analysis():
    """
    æ‰§è¡Œå…¬å¹³æ€§åˆ†æ
    """
    print("=== æ¨¡å‹å…¬å¹³æ€§æ£€æµ‹ ===")
    
    # åŠ è½½è®­ç»ƒæ•°æ®
    train_df = load_training_data_with_predictions()
    if train_df is None:
        return False
    
    # åŠ è½½é¢„æµ‹ç»“æœ
    pred_df = load_prediction_results()
    if pred_df is None:
        return False
    
    # åˆå¹¶æ•°æ®
    print("æ­£åœ¨åˆå¹¶è®­ç»ƒæ•°æ®å’Œé¢„æµ‹ç»“æœ...")
    merged_df = pd.merge(train_df[['Id', 'Label']], pred_df[['Id', 'PredictedProb']], on='Id', how='inner')
    print(f"âœ… æ•°æ®åˆå¹¶å®Œæˆï¼Œå½¢çŠ¶: {merged_df.shape}")
    
    if len(merged_df) == 0:
        print("âŒ åˆå¹¶åçš„æ•°æ®ä¸ºç©º")
        return False
    
    # è¯†åˆ«æ½œåœ¨çš„æ•æ„Ÿç‰¹å¾
    print("\n=== è¯†åˆ«æ½œåœ¨æ•æ„Ÿç‰¹å¾ ===")
    sensitive_features = identify_potential_sensitive_features(train_df)
    print(f"ğŸ” è¯†åˆ«åˆ°çš„æ½œåœ¨æ•æ„Ÿç‰¹å¾: {sensitive_features}")
    
    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ•æ„Ÿç‰¹å¾ï¼Œä½¿ç”¨ä¸€äº›é»˜è®¤çš„ç‰¹å¾è¿›è¡Œåˆ†æ
    if not sensitive_features:
        # æŸ¥æ‰¾å¯èƒ½çš„åˆ†ç»„ç‰¹å¾
        potential_group_features = []
        for col in train_df.columns:
            # æŸ¥æ‰¾ç±»åˆ«å‹ç‰¹å¾æˆ–å…·æœ‰æœ‰é™å”¯ä¸€å€¼çš„ç‰¹å¾
            if col not in ['Id', 'Label'] and train_df[col].dtype == 'object':
                unique_count = train_df[col].nunique()
                if 2 <= unique_count <= 20:  # é™åˆ¶åœ¨åˆç†èŒƒå›´å†…
                    potential_group_features.append(col)
            elif col not in ['Id', 'Label'] and train_df[col].dtype in ['int64', 'float64']:
                unique_count = train_df[col].nunique()
                if 2 <= unique_count <= 10:  # å¯¹äºæ•°å€¼å‹ï¼Œé™åˆ¶åœ¨æ›´å°èŒƒå›´å†…
                    potential_group_features.append(col)
        
        sensitive_features = potential_group_features[:5]  # å–å‰5ä¸ª
        print(f"ğŸ”„ ä½¿ç”¨é»˜è®¤åˆ†ç»„ç‰¹å¾: {sensitive_features}")
    
    if not sensitive_features:
        print("âš ï¸ æœªæ‰¾åˆ°ä»»ä½•æ½œåœ¨çš„æ•æ„Ÿç‰¹å¾ï¼Œå°†ä½¿ç”¨Idçš„é¦–å­—ç¬¦ä½œä¸ºç¤ºä¾‹åˆ†ç»„")
        # åˆ›å»ºä¸€ä¸ªç¤ºä¾‹åˆ†ç»„ç‰¹å¾
        train_df['example_group'] = train_df['Id'].astype(str).str[0]
        sensitive_features = ['example_group']
    
    # åˆ›å»ºå…¬å¹³æ€§æ£€æµ‹å™¨
    fairness_checker = FairnessChecker(merged_df, label_col='Label', prediction_col='PredictedProb')
    
    # ç”Ÿæˆå…¬å¹³æ€§æŠ¥å‘Š
    print(f"\n=== æ‰§è¡Œå…¬å¹³æ€§æ£€æµ‹ ===")
    fairness_report = fairness_checker.generate_fairness_report(
        protected_attrs=sensitive_features,
        threshold=0.5,
        fairness_threshold=0.1  # 10%çš„å·®å¼‚é˜ˆå€¼
    )
    
    # ä¿å­˜æŠ¥å‘Š
    report_path = "output/fairness_report.csv"
    save_fairness_report(fairness_report, report_path)
    
    # æ‰“å°æ‘˜è¦
    print_fairness_summary(fairness_report)
    
    return True

def save_fairness_report(report, file_path):
    """
    ä¿å­˜å…¬å¹³æ€§æŠ¥å‘Šåˆ°CSVæ–‡ä»¶
    
    å‚æ•°:
    report: å…¬å¹³æ€§æŠ¥å‘Šå­—å…¸
    file_path: ä¿å­˜è·¯å¾„
    """
    try:
        # å°†æŠ¥å‘Šè½¬æ¢ä¸ºDataFrameæ ¼å¼
        rows = []
        
        for attr, attr_report in report.items():
            if 'error' in attr_report:
                rows.append({
                    'protected_attribute': attr,
                    'error': attr_report['error']
                })
                continue
                
            # ä¸ºæ¯ä¸ªå…¬å¹³æ€§æŒ‡æ ‡åˆ›å»ºä¸€è¡Œ
            metrics = ['demographic_parity', 'equal_opportunity', 'equalized_odds', 'predictive_parity']
            for metric in metrics:
                if metric in attr_report:
                    metric_data = attr_report[metric]
                    row = {
                        'protected_attribute': attr,
                        'metric': metric,
                        'max_difference': metric_data.get('max_difference', 
                                                       metric_data.get('max_tpr_difference', 0) or 
                                                       metric_data.get('max_fpr_difference', 0)),
                        'bias_detected': attr_report['bias_detected'].get(f'{metric}_bias', False),
                        'overall_bias': attr_report.get('overall_bias', False)
                    }
                    rows.append(row)
        
        if rows:
            report_df = pd.DataFrame(rows)
            report_df.to_csv(file_path, index=False, encoding='utf-8')
            print(f"âœ… å…¬å¹³æ€§æŠ¥å‘Šå·²ä¿å­˜åˆ°: {file_path}")
        else:
            print("âš ï¸ æ²¡æœ‰æ•°æ®å¯ä¿å­˜åˆ°å…¬å¹³æ€§æŠ¥å‘Š")
            
    except Exception as e:
        print(f"âŒ ä¿å­˜å…¬å¹³æ€§æŠ¥å‘Šæ—¶å‡ºé”™: {e}")

def print_fairness_summary(report):
    """
    æ‰“å°å…¬å¹³æ€§æ£€æµ‹æ‘˜è¦
    
    å‚æ•°:
    report: å…¬å¹³æ€§æŠ¥å‘Šå­—å…¸
    """
    print("\n=== å…¬å¹³æ€§æ£€æµ‹æ‘˜è¦ ===")
    
    overall_bias_found = False
    
    for attr, attr_report in report.items():
        if 'error' in attr_report:
            print(f"âŒ å±æ€§ '{attr}': {attr_report['error']}")
            continue
            
        print(f"\nğŸ” å±æ€§ '{attr}':")
        
        # æ£€æŸ¥æ˜¯å¦å‘ç°åè§
        if attr_report.get('overall_bias', False):
            print(f"  âš ï¸  å‘ç°åè§!")
            overall_bias_found = True
        else:
            print(f"  âœ… æœªå‘ç°æ˜æ˜¾åè§")
        
        # æ‰“å°å„æŒ‡æ ‡çš„æœ€å¤§å·®å¼‚
        metrics_info = {
            'demographic_parity': 'äººå£ç»Ÿè®¡å­¦å…¬å¹³æ€§',
            'equal_opportunity': 'æœºä¼šå¹³ç­‰',
            'equalized_odds': 'å‡è¡¡æœºä¼š',
            'predictive_parity': 'é¢„æµ‹å…¬å¹³æ€§'
        }
        
        for metric_key, metric_name in metrics_info.items():
            if metric_key in attr_report:
                metric_data = attr_report[metric_key]
                max_diff = metric_data.get('max_difference', 
                                         metric_data.get('max_tpr_difference', 0) or 
                                         metric_data.get('max_fpr_difference', 0))
                bias_detected = attr_report['bias_detected'].get(f'{metric_key}_bias', False)
                
                status = "âš ï¸  å­˜åœ¨åè§" if bias_detected else "âœ… å…¬å¹³"
                print(f"    {metric_name}: æœ€å¤§å·®å¼‚ {max_diff:.4f} ({status})")
    
    if overall_bias_found:
        print("\nğŸš¨ æ£€æµ‹åˆ°æ¨¡å‹ä¸­å­˜åœ¨æ½œåœ¨çš„å…¬å¹³æ€§åè§ï¼Œè¯·è¿›ä¸€æ­¥åˆ†æå¹¶é‡‡å–æªæ–½æ”¹è¿›æ¨¡å‹ã€‚")
    else:
        print("\nâœ… æ¨¡å‹åœ¨æ£€æµ‹çš„å±æ€§ä¸Šæœªå‘ç°æ˜æ˜¾çš„å…¬å¹³æ€§åè§ã€‚")

def main():
    """
    ä¸»å‡½æ•°
    """
    print("å¼€å§‹æ‰§è¡Œæ¨¡å‹å…¬å¹³æ€§æ£€æµ‹...")
    
    success = perform_fairness_analysis()
    
    if success:
        print("\nğŸ‰ å…¬å¹³æ€§æ£€æµ‹å®Œæˆ!")
        print("è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ° output/fairness_report.csv")
    else:
        print("\nğŸ’¥ å…¬å¹³æ€§æ£€æµ‹å¤±è´¥!")
        sys.exit(1)

if __name__ == "__main__":
    main()